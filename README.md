ds-advent
=========

A Rust client library for [Maelstrom](https://github.com/jepsen-io/maelstrom) and solutions for fly.io's set of [distributed systems challenges](https://fly.io/dist-sys/1/).

## About the "About the 'About the Client Library' Below" Below

That design turned out to be about 90% of the way there, but something I thought was a plus turned out to be a significant flaw: separating the logic that gets run on the receipt of RPC calls from the logic that gets run on the receipt of replies turned out to require too much onerous (and custom per-challenge) bookkeeping, and it involved a lot of cognitive overhead to keep track of the lifecycle of an incoming client request in cases where those involved sending out requests to neighbor nodes and waiting on a reply. I didn't bother migrating over earlier challenges this time, but everything from challenge 4 on is implemented with this version of the node client library and it's fairly pleasant. RPC calls now store a record in a map containing an mpsc `Sender` and a `JoinHandle`. The idea is that the logic for servicing a request, that may involve sending out requests to neighbor nodes and waiting on responses, takes place in a top-level async task. Since we may need to mutate node state as a result of a reply that we receive, but since we don't want to go through all the ceremony of sharing a reference to the node struct between tasks/potentially across threads, this new task holds a `Sender` that can send pre-defined commands to the node, which it will pick up and execute in the course of running its event loop. In turn, if the node gets a reply with an `in_reply_to` field matching a key in the map holding reply records, it will forward that reply to the running task via the `Sender` held in that record. The `JoinHandle` is for another task that sends a timeout notification in lieu of the reply being waited on -- if we get the reply first, we can just abort the timeout task without issue. This setup allows all the logic involved in servicing a reply to be specified in the same place and in a synchronous-appearing way, which is after all the whole promise of async/await. There's still slightly more boilerplate for setting up those request-servicing tasks than I'd like, since we always need to e.g. clone the command `Sender` each time so it can be moved into the task, but the solutions to that that have come to mind so far feel too brittle to be justified.

On top of that change I was contemplating wrapping the node id info in some sort of index-based wrapper so that e.g. there wouldn't be any borrow conflicts in trying to run mutating methods on the node in a loop that iterates over all the cluster node ids, and also no need to clone all the node id strings just to serve that use case, but it seems like it would involve plumbing it through a large portion of the node library in a way that I think would harm the clarity of these toy implementations. It seemed like a better deal to pay the cost of a few clones in exchange.

Lastly, I stopped being lazy and stopped plumbing the external message types all the way through, instead parsing them at the edge to add some guarantees that Maelstrom's protocol technically doesn't enforce (e.g. non-nullable src/dest fields) but that are practically guaranteed and that the challenge logic relies on, resulting in many fewer checks to see whether an `Option` is populated. I also tightened up a lot of method signatures to more idiomatically convey that they may clone their arguments, so those arguments are no longer coyly passed as references. I've been using Rust for a bit, but this is my first attempt at anything like general-purpose library code, so it's been a great learning experience for how to do that idiomatically and in a way that rules out as much as possible the representation of invalid states.

## About the "About the Client Library" Below

I was prepared for it to be a slightly gnarly interface to use in a Rust async context, but it was too gnarly, so I redid the client in exactly the way I proposed in the first paragraph. I know there are existing ones out there, but again, I thought it'd be a fun exercise itself. I'm pretty happy with it -- some of the type signatures are verbose, to put it lightly (though not as bad as they might ahave been without 1.75's inclusion of returning `impl Trait` in trait definitions), and I haven't yet come up with a nice way to not have to implement a method incrementing the `msg_id` for each new project, but it enables writing straightforward and simple code for the actual challenge logic, which seems like the mark of a successful library. It's a bit of overkill for echo, but the overhead is constant and gets amortized quickly as the inherent problem complexity grows.

## About the Client Library

I thought it'd be an interesting, quick way to get my head in place to attempt a translation of fly.io's [Go client](https://pkg.go.dev/github.com/jepsen-io/maelstrom/demo/go) to Rust that maintained, as well as possible, the clear-box semantics of the Go library. That library is simple enough that a more idiomatic async implementation maintaining adherence to the Maelstrom protocol seems pretty straightforward -- CSP-style tasks owning resources like stdin/stdout that would otherwise be protected by locks (no tokio Mutex!) and communicating over channels, the Node equivalent handling only message ser/de and delegating behavior to a generic implementor, with that behavior being staticly dispatched instead of the dynamic handler registration of the Go lib -- so a superficially naive translation might make for a good learning experience.

I figured some of the things the Go library does might require some contortions to preserve -- the way handlers defined in the node's originating scope close over the node, for example, which was just much easier to solve by having my handlers take a reference to the node as an argument -- and indeed they did. To make the node `Send`, nearly every field has to be wrapped in a mutex, sometimes unfortunately Tokio mutexes in cases where not holding a lock over an await point would require a significant redesign, at which point why not just abandon this mercurial project and do it the idiomatic way; handlers need to be able to call async methods on the node, so without async closures they return a `BoxedFuture` to tie their return value's lifetime to the node's and allow the handler's calling context to await their result; `Send + Sync + 'static` bounds are everywhere.

On the plus side, this implementation does add at least a little type safety -- uninitialized vs. initialized nodes are represented via typestates that prevent incoherent actions like initializing an initialized node or sending a message from a node with no ID, and reply callbacks implement `FnOnce`. This also means that the semantics in the small of the Go library aren't precisely preserved, since that library will happily handle an init message to an initialized node, but it's compliant with the contract expected by Maelstrom.
